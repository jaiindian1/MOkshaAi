{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPSM9tmBr7yJTKe46E6hUk5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaiindian1/MOkshaAi/blob/main/15dec25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_pqQi6qdUFco",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88958c26-7759-4ef8-b39e-1fb4b11cea43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ An error occurred during extraction: File is not a zip file\n",
            "\n",
            "--- Data Path Ready ---\n",
            "The raw JSONL file is ready for processing at: None\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import zipfile\n",
        "import os\n",
        "zip_file ='medicare_inbound.zip'\n",
        "extraction_folder ='medicare_data_unzip'\n",
        "def extraction_zip_file(zip_path,extract_to_folder):\n",
        "  try:\n",
        "    os.makedirs(extract_to_folder, exist_ok=True)\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "\n",
        "              # Extract all contents into the specified folder\n",
        "              zip_ref.extractall(extract_to_folder)\n",
        "\n",
        "              # Get the name of the file that was extracted (usually it's the same name, but .jsonl)\n",
        "              extracted_files = zip_ref.namelist()\n",
        "\n",
        "              print(\"✅ Extraction Complete!\")\n",
        "              print(f\"Contents saved to: **{extract_to_folder}**\")\n",
        "              print(f\"Extracted files: {extracted_files}\")\n",
        "\n",
        "              # Return the full path to the crucial JSONL file inside the new folder\n",
        "              if extracted_files:\n",
        "                  return os.path.join(extract_to_folder, extracted_files[0])\n",
        "              else:\n",
        "                  return None\n",
        "\n",
        "  except FileNotFoundError:\n",
        "      print(f\"❌ ERROR: Zipped file not found at {zip_path}. Did you upload 'medicare_inbound.zip'?\")\n",
        "      return None\n",
        "  except Exception as e:\n",
        "      print(f\"❌ An error occurred during extraction: {e}\")\n",
        "      return None\n",
        "\n",
        "# --- Step 1: Run the Extraction ---\n",
        "raw_jsonl_path = extraction_zip_file(zip_file, extraction_folder)\n",
        "\n",
        "# We now know the path to the raw, unzipped .jsonl file!\n",
        "print(f\"\\n--- Data Path Ready ---\")\n",
        "print(f\"The raw JSONL file is ready for processing at: {raw_jsonl_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_file_path = 'medicare_data_unzip/medicare_inbound.jsonl' # Example path to the raw, complex data\n",
        "destination_file_path = 'clean_medicare_transcripts.txt'        # Path to the clean, simple text file\n",
        "\n",
        "def convert_to_txt(source_file_path, destination_file_path):\n",
        "\n",
        "    try:\n",
        "        # 1. E (Extract): Open the original JSONL file for reading ('r')\n",
        "        with open(source_file_path, 'r', encoding='utf-8') as source_file:\n",
        "\n",
        "            # 3. L (Load): Open the new TXT file for writing ('w')\n",
        "            with open(destination_file_path, 'w', encoding='utf-8') as dest_file:\n",
        "\n",
        "                lines_processed = 0\n",
        "\n",
        "                # Loop through every single line (conversation) in the source file\n",
        "                for line in source_file:\n",
        "\n",
        "                    # 2. T (Transform) - This is the key step!\n",
        "                    # A. Convert the line (which is a string) into a Python dictionary.\n",
        "                    # Example: '{ \"text\": \"Hello, I need help...\", \"conf\": 0.9 }'\n",
        "                    # becomes a dictionary in Python.\n",
        "                    json_data = json.loads(line)\n",
        "\n",
        "                    # B. Extract only the value we want: the clean conversation text.\n",
        "                    # We discard the \"confidence\" and \"words\" lists.\n",
        "                    transcript = json_data.get('text', '')\n",
        "\n",
        "                    # C. Load the clean text into the destination file.\n",
        "                    dest_file.write(transcript + '\\n')\n",
        "\n",
        "                    lines_processed += 1\n",
        "\n",
        "        print(f\"✅ Conversion complete! {lines_processed} conversations processed.\")\n",
        "        print(f\"Clean data saved to: {destination_file_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ An error occurred during conversion: {e}\")"
      ],
      "metadata": {
        "id": "VLPH_PWIcfso"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}